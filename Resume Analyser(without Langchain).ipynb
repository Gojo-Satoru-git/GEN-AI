{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqG32KRXY4ovvyuchafsCu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gojo-Satoru-git/GEN-AI/blob/main/Resume%20Analyser(without%20Langchain).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall numpy\n",
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RUqa14JFG4s",
        "outputId": "2a3e551e-659f-44e4-aa9f-c0a35f397368"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 2.0.2\n",
            "Uninstalling numpy-2.0.2:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/bin/numpy-config\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-2.0.2.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1-0352e75f.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99-934c22de.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libscipy_openblas64_-99b71e71.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled numpy-2.0.2\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R3HcOjwFg58",
        "outputId": "85030df0-361b-4bb8-a5c1-e3d0480ba5bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/232.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xscQ32SECV9y",
        "outputId": "efd2c7f8-5d18-4431-eb29-7f7077e9c5ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"Name\": \"John \",\n",
            "    \"Contact\": [\n",
            "        \"johndoe@example.com\",\n",
            "        \"+1 234 567 8901\"\n",
            "    ],\n",
            "    \"Skills\": [\n",
            "        \"Cloth Designing\",\n",
            "        \"Textile Selection\",\n",
            "        \"Industrial Fashion Trends\",\n",
            "        \"Pattern Making\",\n",
            "        \"Sewing\",\n",
            "        \"Garment Construction\",\n",
            "        \"Adobe Illustrator\",\n",
            "        \"Photoshop\"\n",
            "    ],\n",
            "    \"Education\": \"Bachelor of Arts in Fashion Design\",\n",
            "    \"Experience\": \"\",\n",
            "    \"Certifications\": \"Certified Fashion Designer \",\n",
            "    \"Matching Skills\": [\n",
            "        \"Cloth Designing\",\n",
            "        \"Textile Selection\",\n",
            "        \"Industrial Fashion Trends\",\n",
            "        \"Garment Construction\"\n",
            "    ],\n",
            "    \"Fit Score\": 50.0\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import torch\n",
        "import docx2txt\n",
        "import PyPDF2\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load NLP model from Hugging Face (BERT for Named Entity Recognition)\n",
        "ner_pipeline = pipeline(\"ner\", model=\"dslim/bert-base-NER\")\n",
        "embedding_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "def extract_text_from_resume(file_path):\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        text = \"\"\n",
        "        with open(file_path, \"rb\") as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() + \" \"\n",
        "    elif ext in [\".doc\", \".docx\"]:\n",
        "        text = docx2txt.process(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file format\")\n",
        "    return text.strip()\n",
        "def extract_resume_details(text):\n",
        "    extracted_info = {\n",
        "        \"Name\": \"\",\n",
        "        \"Contact\": [],\n",
        "        \"Skills\": [],\n",
        "        \"Education\": \"\",\n",
        "        \"Experience\": \"\",\n",
        "        \"Certifications\": \"\"\n",
        "    }\n",
        "\n",
        "    # Extract Name\n",
        "    ner_results = ner_pipeline(text)\n",
        "    for entity in ner_results:\n",
        "        if entity['entity'] == \"B-PER\":\n",
        "            extracted_info[\"Name\"] += entity['word'] + \" \"\n",
        "\n",
        "    # Extract Contact Information\n",
        "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', text)\n",
        "    phones = re.findall(r'\\+?\\d[\\d\\s\\-()]{8,}\\d', text)\n",
        "    extracted_info[\"Contact\"] = emails + phones\n",
        "\n",
        "    # Extract Skills\n",
        "    skill_keywords = [\"Cloth Designing\", \"Textile Selection\", \"Industrial Fashion Trends\",\n",
        "                      \"Pattern Making\", \"Sewing\", \"Garment Construction\", \"Adobe Illustrator\",\n",
        "                      \"Photoshop\"]\n",
        "    extracted_info[\"Skills\"] = [word for word in skill_keywords if word.lower() in text.lower()]\n",
        "\n",
        "    # Extract Education\n",
        "    education_match = re.search(r\"(Bachelor|Master|PhD) of [A-Za-z ]+\", text)\n",
        "    if education_match:\n",
        "        extracted_info[\"Education\"] = education_match.group()\n",
        "\n",
        "    # Extract Experience\n",
        "    experience_match = re.search(r\"(\\d{1,2}\\+?) years? of experience\", text)\n",
        "    if experience_match:\n",
        "        extracted_info[\"Experience\"] = experience_match.group()\n",
        "\n",
        "    # Extract Certifications\n",
        "    cert_match = re.search(r\"Certified [A-Za-z ]+\", text)\n",
        "    if cert_match:\n",
        "        extracted_info[\"Certifications\"] = cert_match.group()\n",
        "\n",
        "    return extracted_info\n",
        "\n",
        "\n",
        "def compare_skills(extracted_skills, job_description):\n",
        "    job_embedding = embedding_model.encode(job_description, convert_to_tensor=True)\n",
        "    skill_embeddings = [embedding_model.encode(skill, convert_to_tensor=True) for skill in extracted_skills]\n",
        "\n",
        "    matching_skills = []\n",
        "    for skill, emb in zip(extracted_skills, skill_embeddings):\n",
        "        similarity = util.pytorch_cos_sim(job_embedding, emb).item()\n",
        "        if similarity > 0.5:  # Threshold for relevance\n",
        "            matching_skills.append(skill)\n",
        "\n",
        "    score = (len(matching_skills) / len(extracted_skills)) * 100 if extracted_skills else 0\n",
        "    return matching_skills, round(score, 2)\n",
        "\n",
        "def analyze_resume(file_path, job_description):\n",
        "    text = extract_text_from_resume(file_path)\n",
        "    extracted_info = extract_resume_details(text)\n",
        "\n",
        "    matching_skills, fit_score = compare_skills(extracted_info.get(\"Skills\", []), job_description)\n",
        "    extracted_info[\"Matching Skills\"] = matching_skills\n",
        "    extracted_info[\"Fit Score\"] = fit_score\n",
        "\n",
        "    return json.dumps(extracted_info, indent=4)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    file_path = \"Resume_Sample.pdf\"  # Change to your actual file path\n",
        "    job_desc = \"We are looking for a Cloth designers with industrial experiance\"\n",
        "    result = analyze_resume(file_path, job_desc)\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CXr8KwIICZM4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}